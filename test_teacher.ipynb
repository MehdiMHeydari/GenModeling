{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test VP Diffusion Teacher — Darcy Flow\n",
    "\n",
    "Generates samples from the trained teacher model using DDIM sampling\n",
    "and compares them to real Darcy Flow fields.\n",
    "\n",
    "**Run this while Stage 2 (CD) is training to verify the teacher works.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "assert torch.cuda.is_available(), \"Enable GPU: Runtime > Change runtime type > GPU\"\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install -q omegaconf einops h5py\n",
    "\n",
    "import os\n",
    "REPO_DIR = '/content/GenModeling'\n",
    "if os.path.exists(REPO_DIR):\n",
    "    !git -C {REPO_DIR} pull\n",
    "else:\n",
    "    !git clone https://github.com/MehdiMHeydari/GenModeling.git {REPO_DIR}\n",
    "\n",
    "import sys\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)\n",
    "print(\"Ready.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import torch as th\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.models.networks.unet.unet import UNetModelWrapper as UNetModel\n",
    "from src.models.vp_diffusion import VPDiffusionModel\n",
    "from src.models.diffusion_utils import ddim_step\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "print(\"Imports OK.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CONFIG — must match what you used for training\n",
    "# ============================================================\n",
    "DATA_SHAPE = (1, 128, 128)\n",
    "DATA_PATH = \"/content/drive/MyDrive/2D_DarcyFlow_beta1.0_Train.hdf5\"\n",
    "TEACHER_SAVE_DIR = \"/content/drive/MyDrive/cd_darcy/teacher\"\n",
    "SCHEDULE_S = 0.008\n",
    "\n",
    "UNET_CFG = dict(\n",
    "    dim=list(DATA_SHAPE),\n",
    "    channel_mult=\"1, 2, 4, 4\",\n",
    "    num_channels=64,\n",
    "    num_res_blocks=2,\n",
    "    num_head_channels=32,\n",
    "    attention_resolutions=\"32\",\n",
    "    dropout=0.0,\n",
    "    use_new_attention_order=True,\n",
    "    use_scale_shift_norm=True,\n",
    "    class_cond=False,\n",
    "    num_classes=None,\n",
    ")\n",
    "\n",
    "# Sampling config\n",
    "DDIM_STEPS = 50          # number of DDIM steps (more = better quality, slower)\n",
    "NUM_SAMPLES = 16         # how many to generate\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Pick checkpoint (use the last one)\n",
    "TEACHER_CKPT = os.path.join(TEACHER_SAVE_DIR, \"checkpoint_175.pt\")\n",
    "print(f\"Will load: {TEACHER_CKPT}\")\n",
    "print(f\"Exists: {os.path.exists(TEACHER_CKPT)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# LOAD TEACHER MODEL\n",
    "# ============================================================\n",
    "network = UNetModel(**UNET_CFG)\n",
    "teacher = VPDiffusionModel(network=network, schedule_s=SCHEDULE_S, infer=True)\n",
    "\n",
    "state = th.load(TEACHER_CKPT, map_location='cpu', weights_only=True)\n",
    "teacher.network.load_state_dict(state['model_state_dict'])\n",
    "teacher.to(DEVICE)\n",
    "teacher.eval()\n",
    "print(f\"Loaded teacher from epoch {state['epoch']}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in teacher.parameters()):,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# GENERATE SAMPLES VIA DDIM\n",
    "# ============================================================\n",
    "# DDIM: start from z_1 ~ N(0,I), step from t=1 down to t=0\n",
    "# At each step: predict x_hat, then take DDIM step to next t\n",
    "# ============================================================\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "C, H, W = DATA_SHAPE\n",
    "all_samples = []\n",
    "rounds = (NUM_SAMPLES + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "# Time steps: linearly spaced from 1.0 down to ~0\n",
    "ts = th.linspace(1.0, 0.0, DDIM_STEPS + 1, device=DEVICE)\n",
    "\n",
    "print(f\"Generating {NUM_SAMPLES} samples with {DDIM_STEPS} DDIM steps...\")\n",
    "\n",
    "with th.no_grad():\n",
    "    for r in range(rounds):\n",
    "        n = min(BATCH_SIZE, NUM_SAMPLES - r * BATCH_SIZE)\n",
    "        z = th.randn(n, C, H, W, device=DEVICE)\n",
    "\n",
    "        for i in tqdm(range(DDIM_STEPS), desc=f\"Batch {r+1}/{rounds}\", leave=False):\n",
    "            t_now = ts[i]\n",
    "            t_next = ts[i + 1]\n",
    "\n",
    "            t_batch = th.full((n,), t_now.item(), device=DEVICE)\n",
    "            s_batch = th.full((n,), t_next.item(), device=DEVICE)\n",
    "\n",
    "            x_hat = teacher.predict_x(z, t_batch)\n",
    "            z = ddim_step(x_hat, z, t_batch, s_batch, SCHEDULE_S)\n",
    "\n",
    "        all_samples.append(z.cpu())\n",
    "        print(f\"  Batch {r+1}/{rounds} done\")\n",
    "\n",
    "all_samples = th.cat(all_samples, dim=0)[:NUM_SAMPLES]\n",
    "print(f\"Generated {all_samples.shape[0]} samples, shape: {all_samples.shape}\")\n",
    "print(f\"Normalized range: [{all_samples.min():.4f}, {all_samples.max():.4f}]\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# LOAD REAL DATA FOR COMPARISON\n",
    "# ============================================================\n",
    "with h5py.File(DATA_PATH, 'r') as f:\n",
    "    outputs = np.array(f['tensor']).astype(np.float32)\n",
    "if outputs.ndim == 3:\n",
    "    outputs = outputs[:, np.newaxis, :, :]\n",
    "\n",
    "# Load normalization stats\n",
    "data_min = float(np.load(os.path.join(TEACHER_SAVE_DIR, \"data_min.npy\")))\n",
    "data_max = float(np.load(os.path.join(TEACHER_SAVE_DIR, \"data_max.npy\")))\n",
    "\n",
    "def denormalize(x_norm):\n",
    "    return (x_norm + 1.0) / 2.0 * (data_max - data_min) + data_min\n",
    "\n",
    "# Normalize real data the same way\n",
    "real_norm = 2.0 * (outputs - data_min) / (data_max - data_min) - 1.0\n",
    "test_data = real_norm[1000:]  # test set\n",
    "\n",
    "# Denormalize everything\n",
    "gen_denorm = denormalize(all_samples.numpy())\n",
    "real_denorm = denormalize(test_data)\n",
    "\n",
    "print(f\"Generated (physical): [{gen_denorm.min():.4f}, {gen_denorm.max():.4f}]\")\n",
    "print(f\"Real test  (physical): [{real_denorm.min():.4f}, {real_denorm.max():.4f}]\")\n",
    "print(f\"Real full   (physical): [{outputs.min():.4f}, {outputs.max():.4f}]\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# VISUAL COMPARISON: Generated vs Real\n",
    "# ============================================================\n",
    "n_show = 4\n",
    "fig, axes = plt.subplots(2, n_show, figsize=(4 * n_show, 8))\n",
    "\n",
    "vmin = min(gen_denorm[:n_show].min(), real_denorm[:n_show].min())\n",
    "vmax = max(gen_denorm[:n_show].max(), real_denorm[:n_show].max())\n",
    "\n",
    "for i in range(n_show):\n",
    "    im = axes[0, i].imshow(gen_denorm[i, 0], cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "    axes[0, i].set_title(f'Generated {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "    axes[1, i].imshow(real_denorm[i, 0], cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "    axes[1, i].set_title(f'Real {i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "fig.colorbar(im, ax=axes, shrink=0.6, label='u(x,y)')\n",
    "plt.suptitle(f'VP Diffusion Teacher ({DDIM_STEPS}-step DDIM) vs Real Darcy Flow', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# GRID: All Generated Samples\n",
    "# ============================================================\n",
    "n_grid = min(NUM_SAMPLES, 16)\n",
    "rows = (n_grid + 3) // 4\n",
    "fig, axes = plt.subplots(rows, 4, figsize=(16, 4 * rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    if i < n_grid:\n",
    "        axes[i].imshow(gen_denorm[i, 0], cmap='viridis')\n",
    "        axes[i].set_title(f'Sample {i+1}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(f'All Teacher Samples ({DDIM_STEPS}-step DDIM)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# STATISTICS COMPARISON\n",
    "# ============================================================\n",
    "print(\"=\" * 50)\n",
    "print(\"STATISTICS COMPARISON (physical units)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'':20s} {'Generated':>12s} {'Real (test)':>12s}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Mean':20s} {gen_denorm.mean():12.6f} {real_denorm.mean():12.6f}\")\n",
    "print(f\"{'Std':20s} {gen_denorm.std():12.6f} {real_denorm.std():12.6f}\")\n",
    "print(f\"{'Min':20s} {gen_denorm.min():12.6f} {real_denorm.min():12.6f}\")\n",
    "print(f\"{'Max':20s} {gen_denorm.max():12.6f} {real_denorm.max():12.6f}\")\n",
    "print(f\"{'Median':20s} {np.median(gen_denorm):12.6f} {np.median(real_denorm):12.6f}\")\n",
    "\n",
    "# Per-sample mean comparison\n",
    "gen_means = gen_denorm.mean(axis=(1, 2, 3))\n",
    "real_means = real_denorm.mean(axis=(1, 2, 3))\n",
    "print(f\"\\n{'Per-sample mean':20s}\")\n",
    "print(f\"  Generated:  {gen_means.mean():.6f} +/- {gen_means.std():.6f}\")\n",
    "print(f\"  Real:       {real_means.mean():.6f} +/- {real_means.std():.6f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# HISTOGRAM: Pixel Value Distributions\n",
    "# ============================================================\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.hist(gen_denorm.flatten(), bins=100, alpha=0.6, density=True, label='Generated', color='tab:blue')\n",
    "ax.hist(real_denorm.flatten(), bins=100, alpha=0.6, density=True, label='Real (test)', color='tab:orange')\n",
    "ax.set_xlabel('u(x,y)')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Pixel Value Distribution: Generated vs Real')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
