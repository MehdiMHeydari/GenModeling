{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test CD Student — Darcy Flow\n",
    "\n",
    "Generates samples from the Consistency Model student using **only 2 steps**\n",
    "and compares to real data + teacher (50-step DDIM) quality.\n",
    "\n",
    "**Run this in a separate tab while CD training continues.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "assert torch.cuda.is_available(), \"Enable GPU: Runtime > Change runtime type > GPU\"\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install -q omegaconf einops h5py\n",
    "\n",
    "import os\n",
    "REPO_DIR = '/content/GenModeling'\n",
    "if os.path.exists(REPO_DIR):\n",
    "    !git -C {REPO_DIR} pull\n",
    "else:\n",
    "    !git clone https://github.com/MehdiMHeydari/GenModeling.git {REPO_DIR}\n",
    "\n",
    "import sys\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)\n",
    "print(\"Ready.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import torch as th\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.models.networks.unet.unet import UNetModelWrapper as UNetModel\n",
    "from src.models.vp_diffusion import VPDiffusionModel\n",
    "from src.models.consistency_models import MultistepConsistencyModel\n",
    "from src.inference.samplers import MultistepCMSampler\n",
    "from src.models.diffusion_utils import ddim_step\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "print(\"Imports OK.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "DATA_SHAPE = (1, 128, 128)\n",
    "DATA_PATH = \"/content/drive/MyDrive/2D_DarcyFlow_beta1.0_Train.hdf5\"\n",
    "TEACHER_SAVE_DIR = \"/content/drive/MyDrive/cd_darcy/teacher\"\n",
    "CD_SAVE_DIR = \"/content/drive/MyDrive/cd_darcy/student\"\n",
    "SCHEDULE_S = 0.008\n",
    "STUDENT_STEPS = 2\n",
    "\n",
    "UNET_CFG = dict(\n",
    "    dim=list(DATA_SHAPE),\n",
    "    channel_mult=\"1, 2, 4, 4\",\n",
    "    num_channels=64,\n",
    "    num_res_blocks=2,\n",
    "    num_head_channels=32,\n",
    "    attention_resolutions=\"32\",\n",
    "    dropout=0.0,\n",
    "    use_new_attention_order=True,\n",
    "    use_scale_shift_norm=True,\n",
    "    class_cond=False,\n",
    "    num_classes=None,\n",
    ")\n",
    "\n",
    "NUM_SAMPLES = 16\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# --- Pick the latest CD checkpoint ---\n",
    "# List what's available\n",
    "cd_ckpts = sorted([f for f in os.listdir(CD_SAVE_DIR) if f.startswith('checkpoint_') and f.endswith('.pt')])\n",
    "print(\"Available CD checkpoints:\", cd_ckpts)\n",
    "\n",
    "# Use the latest one\n",
    "CD_CKPT = os.path.join(CD_SAVE_DIR, cd_ckpts[-1])\n",
    "print(f\"\\nUsing: {CD_CKPT}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# LOAD CD STUDENT MODEL\n",
    "# ============================================================\n",
    "network = UNetModel(**UNET_CFG)\n",
    "cm = MultistepConsistencyModel(\n",
    "    network=network,\n",
    "    student_steps=STUDENT_STEPS,\n",
    "    schedule_s=SCHEDULE_S,\n",
    "    infer=True,\n",
    ")\n",
    "\n",
    "state = th.load(CD_CKPT, map_location='cpu', weights_only=True)\n",
    "cm.network.load_state_dict(state['model_state_dict'])\n",
    "if 'ema_state_dict' in state:\n",
    "    cm.ema_network.load_state_dict(state['ema_state_dict'])\n",
    "    print(\"Loaded EMA weights (will use for sampling)\")\n",
    "cm.to(DEVICE)\n",
    "cm.eval()\n",
    "print(f\"Loaded student from epoch {state['epoch']}\")\n",
    "print(f\"Student steps: {STUDENT_STEPS} (vs teacher's 50 DDIM steps)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# GENERATE SAMPLES — CM (2 steps!)\n",
    "# ============================================================\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sampler = MultistepCMSampler(cm)\n",
    "C, H, W = DATA_SHAPE\n",
    "all_samples = []\n",
    "rounds = (NUM_SAMPLES + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "print(f\"Generating {NUM_SAMPLES} samples with {STUDENT_STEPS} steps (CM)...\")\n",
    "with th.no_grad():\n",
    "    for r in range(rounds):\n",
    "        n = min(BATCH_SIZE, NUM_SAMPLES - r * BATCH_SIZE)\n",
    "        z = th.randn(n, C, H, W, device=DEVICE)\n",
    "        samples = sampler.sample(z)\n",
    "        all_samples.append(samples.cpu())\n",
    "        print(f\"  Batch {r+1}/{rounds} done\")\n",
    "\n",
    "cm_samples = th.cat(all_samples, dim=0)[:NUM_SAMPLES]\n",
    "print(f\"Generated {cm_samples.shape[0]} samples\")\n",
    "print(f\"Normalized range: [{cm_samples.min():.4f}, {cm_samples.max():.4f}]\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# ALSO GENERATE TEACHER SAMPLES FOR COMPARISON\n",
    "# ============================================================\n",
    "TEACHER_CKPT = os.path.join(TEACHER_SAVE_DIR, \"checkpoint_175.pt\")\n",
    "\n",
    "teacher_net = UNetModel(**UNET_CFG)\n",
    "teacher = VPDiffusionModel(network=teacher_net, schedule_s=SCHEDULE_S, infer=True)\n",
    "t_state = th.load(TEACHER_CKPT, map_location='cpu', weights_only=True)\n",
    "teacher.network.load_state_dict(t_state['model_state_dict'])\n",
    "teacher.to(DEVICE)\n",
    "teacher.eval()\n",
    "\n",
    "DDIM_STEPS = 50\n",
    "ts = th.linspace(1.0, 0.0, DDIM_STEPS + 1, device=DEVICE)\n",
    "teacher_samples = []\n",
    "\n",
    "# Use the SAME initial noise as CM for fair comparison\n",
    "th.manual_seed(42)\n",
    "cm_noise = [th.randn(min(BATCH_SIZE, NUM_SAMPLES - r * BATCH_SIZE), C, H, W) for r in range(rounds)]\n",
    "\n",
    "print(f\"Generating {NUM_SAMPLES} teacher samples with {DDIM_STEPS} DDIM steps...\")\n",
    "with th.no_grad():\n",
    "    for r in range(rounds):\n",
    "        z = cm_noise[r].to(DEVICE)\n",
    "        n = z.shape[0]\n",
    "        for i in tqdm(range(DDIM_STEPS), desc=f\"Batch {r+1}\", leave=False):\n",
    "            t_batch = th.full((n,), ts[i].item(), device=DEVICE)\n",
    "            s_batch = th.full((n,), ts[i+1].item(), device=DEVICE)\n",
    "            x_hat = teacher.predict_x(z, t_batch)\n",
    "            z = ddim_step(x_hat, z, t_batch, s_batch, SCHEDULE_S)\n",
    "        teacher_samples.append(z.cpu())\n",
    "\n",
    "teacher_samples = th.cat(teacher_samples, dim=0)[:NUM_SAMPLES]\n",
    "print(\"Teacher samples done.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# LOAD REAL DATA + DENORMALIZE\n",
    "# ============================================================\n",
    "with h5py.File(DATA_PATH, 'r') as f:\n",
    "    outputs = np.array(f['tensor']).astype(np.float32)\n",
    "if outputs.ndim == 3:\n",
    "    outputs = outputs[:, np.newaxis, :, :]\n",
    "\n",
    "data_min = float(np.load(os.path.join(TEACHER_SAVE_DIR, \"data_min.npy\")))\n",
    "data_max = float(np.load(os.path.join(TEACHER_SAVE_DIR, \"data_max.npy\")))\n",
    "\n",
    "def denormalize(x_norm):\n",
    "    if isinstance(x_norm, th.Tensor):\n",
    "        x_norm = x_norm.numpy()\n",
    "    return (x_norm + 1.0) / 2.0 * (data_max - data_min) + data_min\n",
    "\n",
    "real_norm = 2.0 * (outputs - data_min) / (data_max - data_min) - 1.0\n",
    "test_data = real_norm[1000:]\n",
    "\n",
    "cm_denorm = denormalize(cm_samples)\n",
    "teacher_denorm = denormalize(teacher_samples)\n",
    "real_denorm = denormalize(test_data)\n",
    "\n",
    "print(f\"CM student (physical):  [{cm_denorm.min():.4f}, {cm_denorm.max():.4f}]\")\n",
    "print(f\"Teacher    (physical):  [{teacher_denorm.min():.4f}, {teacher_denorm.max():.4f}]\")\n",
    "print(f\"Real test  (physical):  [{real_denorm.min():.4f}, {real_denorm.max():.4f}]\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 3-ROW COMPARISON: CM (2-step) vs Teacher (50-step) vs Real\n",
    "# ============================================================\n",
    "n_show = 4\n",
    "fig, axes = plt.subplots(3, n_show, figsize=(4 * n_show, 12))\n",
    "\n",
    "vmin = min(cm_denorm[:n_show].min(), teacher_denorm[:n_show].min(), real_denorm[:n_show].min())\n",
    "vmax = max(cm_denorm[:n_show].max(), teacher_denorm[:n_show].max(), real_denorm[:n_show].max())\n",
    "\n",
    "for i in range(n_show):\n",
    "    axes[0, i].imshow(cm_denorm[i, 0], cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "    axes[0, i].set_title(f'CM Student {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "    axes[1, i].imshow(teacher_denorm[i, 0], cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "    axes[1, i].set_title(f'Teacher {i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "    im = axes[2, i].imshow(real_denorm[i, 0], cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "    axes[2, i].set_title(f'Real {i+1}')\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "axes[0, 0].set_ylabel('CM (2 steps)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Teacher (50 steps)', fontsize=12)\n",
    "axes[2, 0].set_ylabel('Real', fontsize=12)\n",
    "\n",
    "fig.colorbar(im, ax=axes, shrink=0.5, label='u(x,y)')\n",
    "plt.suptitle('Consistency Model vs Teacher vs Real Darcy Flow', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# GRID: All CM Student Samples\n",
    "# ============================================================\n",
    "n_grid = min(NUM_SAMPLES, 16)\n",
    "rows = (n_grid + 3) // 4\n",
    "fig, axes = plt.subplots(rows, 4, figsize=(16, 4 * rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    if i < n_grid:\n",
    "        axes[i].imshow(cm_denorm[i, 0], cmap='viridis')\n",
    "        axes[i].set_title(f'CM Sample {i+1}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(f'All CM Student Samples ({STUDENT_STEPS}-step generation)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# STATISTICS COMPARISON\n",
    "# ============================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"STATISTICS COMPARISON (physical units)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'':20s} {'CM (2-step)':>12s} {'Teacher (50)':>12s} {'Real (test)':>12s}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Mean':20s} {cm_denorm.mean():12.6f} {teacher_denorm.mean():12.6f} {real_denorm.mean():12.6f}\")\n",
    "print(f\"{'Std':20s} {cm_denorm.std():12.6f} {teacher_denorm.std():12.6f} {real_denorm.std():12.6f}\")\n",
    "print(f\"{'Min':20s} {cm_denorm.min():12.6f} {teacher_denorm.min():12.6f} {real_denorm.min():12.6f}\")\n",
    "print(f\"{'Max':20s} {cm_denorm.max():12.6f} {teacher_denorm.max():12.6f} {real_denorm.max():12.6f}\")\n",
    "print(f\"{'Median':20s} {np.median(cm_denorm):12.6f} {np.median(teacher_denorm):12.6f} {np.median(real_denorm):12.6f}\")\n",
    "\n",
    "print(f\"\\nPer-sample mean:\")\n",
    "cm_means = cm_denorm.mean(axis=(1,2,3))\n",
    "t_means = teacher_denorm.mean(axis=(1,2,3))\n",
    "r_means = real_denorm.mean(axis=(1,2,3))\n",
    "print(f\"  CM:       {cm_means.mean():.6f} +/- {cm_means.std():.6f}\")\n",
    "print(f\"  Teacher:  {t_means.mean():.6f} +/- {t_means.std():.6f}\")\n",
    "print(f\"  Real:     {r_means.mean():.6f} +/- {r_means.std():.6f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# HISTOGRAM: All Three Distributions\n",
    "# ============================================================\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.hist(cm_denorm.flatten(), bins=100, alpha=0.5, density=True, label=f'CM ({STUDENT_STEPS}-step)', color='tab:green')\n",
    "ax.hist(teacher_denorm.flatten(), bins=100, alpha=0.5, density=True, label='Teacher (50-step)', color='tab:blue')\n",
    "ax.hist(real_denorm.flatten(), bins=100, alpha=0.5, density=True, label='Real (test)', color='tab:orange')\n",
    "ax.set_xlabel('u(x,y)')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Pixel Value Distribution: CM vs Teacher vs Real')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nKey question: Does the CM (2-step) distribution match the Teacher (50-step)?\")\n",
    "print(f\"If yes -> distillation is working, quality is limited by teacher.\")\n",
    "print(f\"If no  -> student needs more training or different hyperparameters.\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
